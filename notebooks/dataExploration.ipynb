{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##importing necessary libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##understanding the dataset\n",
    "## the csv file consists of 4 columns\n",
    "##first column is label which refers to the ploarity if it is hate speech or not\n",
    "## second column is the catefory in which the speech belongs to for e.g General Profanity Violence etc\n",
    "## the third column contains the key word of the sentece\n",
    "## and finally the fourth column is the sentence itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['label','category','key_word','sentence']\n",
    "df = pd.read_csv('./data.csv',names=colnames,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>key_word</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>जोगाउन को लागि</td>\n",
       "      <td>गुठी विधेक ल्याएर ठमेल मा राज गुठि को जग्गा मा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>लखेटनु पछ</td>\n",
       "      <td>दले ले देश सकेछन सबै बेचे र खान सुरू गरेछन अब ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>ससकृती ध्वस्त पार्ने</td>\n",
       "      <td>नेपाल को ससकृती ध्वस्त पार्ने योजना हो यो !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>भुमाफिया</td>\n",
       "      <td>मठ मन्दिर गुम्बा का जग्गा हरु मा भुमाफिया को न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>बेची सके</td>\n",
       "      <td>नेपाल का कल कर्खाना र नदि नाला बेची सके अब मठ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label category              key_word  \\\n",
       "0      1  GENERAL        जोगाउन को लागि   \n",
       "1      1  GENERAL             लखेटनु पछ   \n",
       "2      1  GENERAL  ससकृती ध्वस्त पार्ने   \n",
       "3      1  GENERAL              भुमाफिया   \n",
       "4      1  GENERAL              बेची सके   \n",
       "\n",
       "                                            sentence  \n",
       "0  गुठी विधेक ल्याएर ठमेल मा राज गुठि को जग्गा मा...  \n",
       "1  दले ले देश सकेछन सबै बेचे र खान सुरू गरेछन अब ...  \n",
       "2        नेपाल को ससकृती ध्वस्त पार्ने योजना हो यो !  \n",
       "3  मठ मन्दिर गुम्बा का जग्गा हरु मा भुमाफिया को न...  \n",
       "4  नेपाल का कल कर्खाना र नदि नाला बेची सके अब मठ ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label  category \n",
       "1      GENERAL      1782\n",
       "0      GENERAL      1053\n",
       "       FEEDBACK      428\n",
       "       PROFANITY     299\n",
       "1      VIOLENCE      174\n",
       "0      VIOLENCE      113\n",
       "1      PROFANITY     108\n",
       "       FEEDBACK       78\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['label','category']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We dont necessarily need to find the category of the sentence\n",
    "## so we can get rid of the column\n",
    "## but we need to classify whether the sentences in the category are hate or not\n",
    "## so for this what we can do is:\n",
    "## set all feedback category to 0 label(not hate) \n",
    "## violence to label 1\n",
    "## profanity to label 1\n",
    "## and general will remain as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category']=='FEEDBACK','label']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    506\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['category']=='FEEDBACK'].label.value_counts()\n",
    "##i.e all the labels are now 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category']=='VIOLENCE','label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['category']=='PROFANITY','label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2476\n",
       "0    1559\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>category</th>\n",
       "      <th>key_word</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>जोगाउन को लागि</td>\n",
       "      <td>गुठी विधेक ल्याएर ठमेल मा राज गुठि को जग्गा मा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>लखेटनु पछ</td>\n",
       "      <td>दले ले देश सकेछन सबै बेचे र खान सुरू गरेछन अब ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>ससकृती ध्वस्त पार्ने</td>\n",
       "      <td>नेपाल को ससकृती ध्वस्त पार्ने योजना हो यो !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>भुमाफिया</td>\n",
       "      <td>मठ मन्दिर गुम्बा का जग्गा हरु मा भुमाफिया को न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>GENERAL</td>\n",
       "      <td>बेची सके</td>\n",
       "      <td>नेपाल का कल कर्खाना र नदि नाला बेची सके अब मठ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label category              key_word  \\\n",
       "0      1  GENERAL        जोगाउन को लागि   \n",
       "1      1  GENERAL             लखेटनु पछ   \n",
       "2      1  GENERAL  ससकृती ध्वस्त पार्ने   \n",
       "3      1  GENERAL              भुमाफिया   \n",
       "4      1  GENERAL              बेची सके   \n",
       "\n",
       "                                            sentence  \n",
       "0  गुठी विधेक ल्याएर ठमेल मा राज गुठि को जग्गा मा...  \n",
       "1  दले ले देश सकेछन सबै बेचे र खान सुरू गरेछन अब ...  \n",
       "2        नेपाल को ससकृती ध्वस्त पार्ने योजना हो यो !  \n",
       "3  मठ मन्दिर गुम्बा का जग्गा हरु मा भुमाफिया को न...  \n",
       "4  नेपाल का कल कर्खाना र नदि नाला बेची सके अब मठ ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['category','key_word'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>गुठी विधेक ल्याएर ठमेल मा राज गुठि को जग्गा मा...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>दले ले देश सकेछन सबै बेचे र खान सुरू गरेछन अब ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>नेपाल को ससकृती ध्वस्त पार्ने योजना हो यो !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>मठ मन्दिर गुम्बा का जग्गा हरु मा भुमाफिया को न...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>नेपाल का कल कर्खाना र नदि नाला बेची सके अब मठ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                           sentence\n",
       "0      1  गुठी विधेक ल्याएर ठमेल मा राज गुठि को जग्गा मा...\n",
       "1      1  दले ले देश सकेछन सबै बेचे र खान सुरू गरेछन अब ...\n",
       "2      1        नेपाल को ससकृती ध्वस्त पार्ने योजना हो यो !\n",
       "3      1  मठ मन्दिर गुम्बा का जग्गा हरु मा भुमाफिया को न...\n",
       "4      1  नेपाल का कल कर्खाना र नदि नाला बेची सके अब मठ ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##now we need to get rid of all the english words and the emojis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##code to transliterate english to devnagari\n",
    "\n",
    "hk_dv_unicode = {'M': '\\u0902', 'H': '\\u0903',\n",
    "                 'a': '\\u0905', 'A': '\\u0906', 'i': '\\u0907', 'I': '\\u0908',\n",
    "                 'u': '\\u0909', 'U': '\\u090A', 'R': '\\u090B', 'RR': '\\u0960', 'lR': '\\u090C',\n",
    "                 'e': '\\u090F', 'ai': '\\u0910', 'o': '\\u0913', 'au': '\\u0914',\n",
    "                 'k': '\\u0915', 'kh': '\\u0916', 'g': '\\u0917', 'gh': '\\u0918', 'G': '\\u0919',\n",
    "                 'c': '\\u091A', 'ch': '\\u091B', 'j': '\\u091C', 'jh': '\\u091D', 'J': '\\u091E',\n",
    "                 'T': '\\u091F', 'Th': '\\u0920', 'D': '\\u0921', 'Dh': '\\u0922', 'N': '\\u0923',\n",
    "                 't': '\\u0924', 'th': '\\u0925', 'd': '\\u0926', 'dh': '\\u0927', 'n': '\\u0928',\n",
    "                 'p': '\\u092A', 'ph': '\\u092B', 'b': '\\u092C', 'bh': '\\u092D', 'm': '\\u092E',\n",
    "                 'y': '\\u092F', 'r': '\\u0930', 'l': '\\u0932', 'v': '\\u0935',\n",
    "                 'z': '\\u0936', 'S': '\\u0937', 's': '\\u0938', 'h': '\\u0939',\n",
    "                 \"'\": '\\u093D', 'oM': '\\u0950', ' ': ' ', '|': '\\u0964', '||': '\\u0964'\n",
    "                 }\n",
    "hk_dv_vowel_diacritics = {'A': '\\u093E', 'a': '',\n",
    "                          'i': '\\u093F', 'I': '\\u0940',\n",
    "                          'u': '\\u0941', 'U': '\\u0942',\n",
    "                          'R': '\\u0943', 'RR': '\\u0944',\n",
    "                          'lR': '\\u0962',\n",
    "                          'e': '\\u0947', 'ai': '\\u0948',\n",
    "                          'o': '\\u094b', 'au': '\\u094C'}\n",
    "hk_dv_vowels = ['A', 'a', 'i', 'I', 'u', 'U',\n",
    "                'R', 'RR',\n",
    "                'lR', 'e', 'ai', 'o', 'au']\n",
    "hk_dv_consonants = ['k', 'g', 'G',\n",
    "                    'c', 'j', 'J',\n",
    "                    'T', 'D', 'N',\n",
    "                    't', 'd', 'n',\n",
    "                    'p', 'b', 'm',\n",
    "                    'y', 'r', 'l', 'v',\n",
    "                    'z', 'S', 's', 'h']\n",
    "hk_dv_special_consonants = ['G', 'J', 'N', 'n', 'm',\n",
    "                            'y', 'r', 'l', 'v',\n",
    "                            'z', 'S', 's']\n",
    "hk_dv_diacritics = ['M', 'H', '\\'']\n",
    "hk_dv_punctuation = ['|', '||']\n",
    "\n",
    "\n",
    "def transliterate(input_text):\n",
    "\n",
    "    \"\"\"\n",
    "    :param input_text: Text to be transliterated, written in Harvard-Kyoto.\n",
    "    :return: Text in Devanagari.\n",
    "    \"\"\"\n",
    "\n",
    "    if input_text[-1] != ' ':\n",
    "        input_text = input_text.center(len(input_text) + 2)\n",
    "    output_text = []\n",
    "    i = -1\n",
    "\n",
    "    for letter in input_text:\n",
    "        i += 1\n",
    "        if letter == \" \":\n",
    "            output_text.append(\" \")\n",
    "        elif letter not in hk_dv_unicode:\n",
    "            output_text.append(letter)\n",
    "        else:\n",
    "            if letter in hk_dv_vowels:\n",
    "                if letter == 'a':\n",
    "                    if input_text[i + 1] == 'i':\n",
    "                        if input_text[i - 1] in hk_dv_consonants:\n",
    "                            output_text.append(hk_dv_vowel_diacritics['ai'])\n",
    "                        else:\n",
    "                            output_text.append(hk_dv_unicode['ai'])\n",
    "                    elif input_text[i + 1] == 'u':\n",
    "                        if input_text[i - 1] in hk_dv_consonants:\n",
    "                            output_text.append(hk_dv_vowel_diacritics['au'])\n",
    "                        else:\n",
    "                            output_text.append(hk_dv_unicode['au'])\n",
    "                    else:\n",
    "                        if input_text[i - 1] in hk_dv_consonants:\n",
    "                            output_text.append('')\n",
    "                        else:\n",
    "                            output_text.append(hk_dv_unicode[letter])\n",
    "                elif letter == 'i' or letter == 'u':\n",
    "                    if input_text[i - 1] == 'a':\n",
    "                        continue\n",
    "                    else:\n",
    "                        if input_text[i - 1] in hk_dv_consonants:\n",
    "                            output_text.append(hk_dv_vowel_diacritics[letter])\n",
    "                        else:\n",
    "                            output_text.append(hk_dv_unicode[letter])\n",
    "                elif letter == 'R':\n",
    "                    if input_text[i + 1] == 'R':\n",
    "                        if input_text[i - 1] in hk_dv_consonants:\n",
    "                            output_text.append(hk_dv_vowel_diacritics['RR'])\n",
    "                        else:\n",
    "                            output_text.append(hk_dv_unicode['RR'])\n",
    "                    elif input_text[i - 1] == 'R' or input_text[i - 1] == 'l':\n",
    "                        continue\n",
    "                    else:\n",
    "                        if input_text[i - 1] in hk_dv_consonants:\n",
    "                            output_text.append(hk_dv_vowel_diacritics[letter])\n",
    "                        else:\n",
    "                            output_text.append(hk_dv_unicode[letter])\n",
    "                else:\n",
    "                    if input_text[i - 1] in hk_dv_consonants:\n",
    "                        output_text.append(hk_dv_vowel_diacritics[letter])\n",
    "                    else:\n",
    "                        output_text.append(hk_dv_unicode[letter])\n",
    "            elif letter in hk_dv_consonants:\n",
    "                if letter == 'l' and input_text[i + 1] == 'R':\n",
    "                    if input_text[i - 1] in hk_dv_consonants:\n",
    "                        output_text.append(hk_dv_vowel_diacritics['lR'])\n",
    "                    else:\n",
    "                        output_text.append(hk_dv_unicode['lR'])\n",
    "                elif input_text[i + 1] == 'h' and letter not in hk_dv_special_consonants:\n",
    "                    output_text.append(hk_dv_unicode['%sh' % letter])\n",
    "                elif letter == 'h' and input_text[i - 1] in hk_dv_consonants:\n",
    "                    if input_text[i+1] not in hk_dv_vowels:\n",
    "                        output_text.append('\\u094D')\n",
    "                elif input_text[i + 1] not in hk_dv_vowels:\n",
    "                    output_text.append(hk_dv_unicode[letter])\n",
    "                    output_text.append('\\u094D')\n",
    "                else:\n",
    "                    output_text.append(hk_dv_unicode[letter])\n",
    "            else:\n",
    "                output_text.append(hk_dv_unicode[letter])\n",
    "\n",
    "    output_text = \"\".join(output_text)\n",
    "    output_text = output_text.strip()\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using regular expression to find english words with the sentence\n",
    "\n",
    "import re\n",
    "reg = re.compile(r'[a-zA-Z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roshan\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0       #to keep track of which line we are currently on\n",
    "for line in df.sentence:\n",
    "    words = line.split()  #splitting the line into words\n",
    "    # print(words)\n",
    "    new_line = ''  \n",
    "    for word in words:\n",
    "        try:  #using try catch block because the transliteration throws error if there is two consecutive h\n",
    "            if reg.match(word):\n",
    "                word = transliterate(word)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        new_line += ' '+ word   #adding the word to a new line\n",
    "    df.sentence[i] = new_line   #overwriting the line of df by newline\n",
    "    i += 1 #incrementing the line\n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to detect emojis present in the sentence\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Roshan\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#code similar to the one above to detect english words\n",
    "\n",
    "i = 0 \n",
    "for line in df.sentence:\n",
    "    line = remove_emojis(line)\n",
    "    df.sentence[i] = line \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the csv file\n",
    "df.to_csv('./improved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cf1c168d150e1e104c424516c96890371ac80e69d0ab891e31240b3bf99dce8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
